{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/marcoandre1/introduction-colab/blob/main/TP1_PartieA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1 : Le jeu de données"
      ],
      "metadata": {
        "id": "AZ0hHAEFdaft"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.1 Télécharger le jeu de données\n",
        "\n",
        "Le jeu de données est sous la forme d'un fichier CSV.\n",
        "\n",
        "**Exécutez la cellule ci-dessous pour télécharger le fichier et l'ajouter à votre répertoire actif _Google Colab_.**"
      ],
      "metadata": {
        "id": "BZBTm3MOdgUB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib.request\n",
        "\n",
        "url = 'https://drive.google.com/uc?export=download&id=13ZfF8DjSvqPJkrY93GJTK2l14IwLVLZ0'\n",
        "urllib.request.urlretrieve(url, 'IT_Support_Tickets_FR_200.csv')\n",
        "\n",
        "print('Téléchargement terminé !')"
      ],
      "metadata": {
        "id": "4QYkfZQkcMMq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.2 Créer un _DataFrame_ pour inspecter le jeu de données\n",
        "\n",
        "Un _DataFrame_ est un objet pour représenter un jeu de données venant du module _pandas_. Ce module _Python_ est populaire en IA.\n",
        "\n",
        "Un _DataFrame_ est une interface conviviale pour traiter un jeu de donnée.\n",
        "\n",
        "**Suivez les consignes ci-dessous**\n",
        "1. importez le module `pandas` et donné lui l'alias `pd`\n",
        "2. créez le _DataFrame_\n",
        "  * créez une nouvelle variable nommée `df`\n",
        "  * utilisez la fonction suivante `pd.read_csv(\"IT_Support_Tickets_FR_200.csv\")` pour créer le _DataFrame_ en lisant le jeu de données téléchargé. Affectez la valeur retournée à la variable `df`.\n",
        "3. finalement, ajoutez une dernière ligne qui n'est que le suivant : `df`. Lorsqu'une cellule termine qu'avec le nom d'une variable _DataFrame_, _Colab_ va afficher la _DataFrame_."
      ],
      "metadata": {
        "id": "45nTHePKezkz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Écrivez votre code dans cette cellule ##\n"
      ],
      "metadata": {
        "id": "cINswq3Ldn9Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.3 Les types de problèmes\n",
        "Pour commencer, nous allons nous concentrer sur la **classification par type de problème**.\n",
        "\n",
        "**Exécutez la celulle ci-dessous pour créer un nouveau _DataFrame_ contenant que le type de problème pour chaque exemple du jeu de donnée**."
      ],
      "metadata": {
        "id": "mwwbZpvXlRIj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "colonne_type_problème = df['Type de problème']\n",
        "\n",
        "colonne_type_problème"
      ],
      "metadata": {
        "id": "qWmTMZVxgn9V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Analysons rapidement le jeu de donnée ; apprendre à le connaître peut nous aider à interpréter des résultats avenirs.\n",
        "\n",
        "Nous voulons connaître le nombre d'exemple par classe, par exemple.\n",
        "\n",
        "**Exécutez la cellule ci-dessous pour créer et afficher un nouveau _DataFrame_ avec le compte de chaque type de problème.**\n",
        "\n",
        "Notez qu'il y a un _déséquilibre des classes_ (ex: il y a beaucoup plus de problèmes 'logiciel' que les autres). Ceci n'est pas idéal, mais nous allons continuer tout de même."
      ],
      "metadata": {
        "id": "fN-6px9fmqS8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "compte_problème = colonne_type_problème.value_counts()\n",
        "\n",
        "compte_problème"
      ],
      "metadata": {
        "id": "-Vf5_mFAlb92"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2 : Prétraitement du jeu de données"
      ],
      "metadata": {
        "id": "c1fCaHrYok5e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.1 Extraire les exemples et colonnes pertinents\n",
        "\n",
        "Souvent, nous n'avons pas besoin de toute l'information d'un jeu. Pour notre problème, nous n'avons pas besoin des colonnes «ID Ticket», «Date», «Client», et «Priorité».\n",
        "\n",
        "En ce qui concerne les exemples, _tous les exemples_ nous intéressent.\n",
        "\n",
        "**Complétez la cellule ci-dessous en créant la liste `colonne_à_retirer`. La liste doit contenir le nom des colonnes à retirer.**\n",
        "\n",
        "La fonction `.drop(.)` qui s'applique sur notre _DataFrame `df` va retourner un nouveau _DataFrame_ sans les colonnes fournies."
      ],
      "metadata": {
        "id": "RrBfFKrVopzq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "colonne_à_retirer = # Complétez ici\n",
        "df_classification = df.drop(columns=colonne_à_retirer)\n",
        "\n",
        "df_classification"
      ],
      "metadata": {
        "id": "rovKr0NHoohD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.2 Encodage des classes\n",
        "Allons fournir une séquence à notre modèle et recevoir une classification comme réponse.\n",
        "\n",
        "Nous avions vu comment la séquence de texte se fera transformer en une sequence vecteur de nombre pour le modèle (tokenizer et embedding).\n",
        "\n",
        "Il faut aussi que la classe soit un nombre. Présentement, nos classes sont du texte.\n",
        "\n",
        "Nous allons **encoder** chaque classe en entier.\n",
        "\n",
        "Le module `sklearn.preprocessing` contient un sous-module `LabelEncoder` qui peut facilement faire cette tâche.\n",
        "\n",
        "**Exécutez la cellule ci-dessous**. Un objet `encodeur` est créé et utilisé pour créer un nouveau _DataFrame_ `nouvelle_colonne` contenant les encodages. Cette nouvelle colonne est ajouté à notre `df_classification` avec le nom `Classe`. Il est simple d'ajouter une colonne à un _DateFrame_ !"
      ],
      "metadata": {
        "id": "YoUQtfY0rP1I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "encodeur = LabelEncoder()\n",
        "\n",
        "nouvelle_colonne = encodeur.fit_transform(df_classification['Type de problème'])\n",
        "df_classification['Classe'] = nouvelle_colonne\n",
        "\n",
        "df_classification"
      ],
      "metadata": {
        "id": "5xsAjJEusPij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.3 Splits _train_, _validation_, _test_\n",
        "Dans le cadre de l'entraînement d'un modèle de classification, il est essentiel de diviser les données en trois ensembles distincts : train, validation et test.\n",
        "\n",
        "Le jeu d'entraînement (train) permet au modèle d'apprendre les relations entre les données d'entrée et les étiquettes.\n",
        "\n",
        "Le jeu de validation est utilisé pour ajuster les hyperparamètres et évaluer les performances du modèle pendant l'entraînement, afin d'éviter le surapprentissage (overfitting).\n",
        "\n",
        "Enfin, le jeu de test permet de mesurer objectivement la performance finale du modèle sur des données totalement inédites. Cette séparation garantit une évaluation fiable et réaliste de la capacité du modèle à généraliser à de nouveaux cas, ce qui est fondamental pour toute application en production.\n",
        "\n",
        "Nous allons faire des splits 60/20/20 : 60% du jeu de données sera consacré au jeu d'entraînement, 20% au jeu de validation, et le dernier 20% au jeu de tests."
      ],
      "metadata": {
        "id": "P1vVozMDuPRL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exécuter la cellule ci-dessous** pour créer les splits à l'aide de la fonction `train_test_split` du module `sklearn.model_selection`.\n",
        "\n",
        "Vous obtiendrez 6 nouveau _DataFrame_ :\n",
        "\n",
        "*   120 descriptions pour l'entraînement, 40 descriptions pour la validation, et 40 descriptions pour le test\n",
        "*   120 classes pour l'entraînement, 40 classes pour la validation, et 40 classes pour le test\n",
        "\n",
        "Ils se nomment `X_train`, `X_val`, `X_test` et `y_train`, `y_val`, `y_test`."
      ],
      "metadata": {
        "id": "s3AaDajtvlo0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# caractéristiques et étiquettes\n",
        "X = df_classification['Description'] # nouveau DataFrame avec les descriptions\n",
        "y = df_classification['Classe'] # nouveau DataFrame avec les classes\n",
        "\n",
        "# premier split : 20% test, 80% temporaire\n",
        "X_temp, X_test, y_temp, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# deuxième split: train + validation (à partir de temporaire)\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_temp, y_temp, test_size=0.25, random_state=42, stratify=y_temp\n",
        ")\n",
        "\n",
        "print(len(X_train), len(X_val), len(X_test))\n",
        "print(len(y_train), len(y_val), len(y_test))"
      ],
      "metadata": {
        "id": "FrphVDJFtYHo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3 : _Tokenize_ les descriptions des 3 splits"
      ],
      "metadata": {
        "id": "ke5elSwby6qR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.1 De _DataFrame_ à listes _Python_\n",
        "Nous allons bientôt utiliser un _tokenizer_ pour transformer les descriptions en séquence de _token_. Le _tokenizer_ fonctionnera sur une liste de texte, et non sur un _DataFrame_.\n",
        "\n",
        "**Complétez la cellule ci-dessous pour créer trois listes (entraînement, validation et test). Notez comment la première est réalisée pour vous.**"
      ],
      "metadata": {
        "id": "Ba1HwgM50CsE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_list = X_train.to_list()\n",
        "X_val_list = # complétez ici\n",
        "X_test_list = # complétez ici"
      ],
      "metadata": {
        "id": "WFHbp_vz1fKc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.2 Créer le _tokenizer_ pour _BARThez_\n",
        "\n",
        "**Dans la cellule ci-dessous, importez le module nécessaire et créer le _tokenizer_.**\n",
        "\n",
        "Ce même objet pourra créer les _tokens_ pour les 3 splits."
      ],
      "metadata": {
        "id": "XCcmVpaf10zT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# importer le module\n",
        "\n",
        "# créer le tokenizer\n",
        "#tokenizer = # à compléter"
      ],
      "metadata": {
        "id": "oe8J8FIUsQD5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.3 _Tokenize_ les listes\n",
        "\n",
        "**Utilisez `tokenizer(.)` pour créer les _tokens_ d'entraînement, de validation, et de test.**\n",
        "\n",
        "Donnez premièrement en paramètre la liste à _tokenize_, ensuite donnez les paramètres suivants : `padding=True, truncation=True, return_tensors=\"pt\"`.\n",
        "\n",
        "Exemple : `tokenizer(ma_liste, padding=True, truncation=True, return_tensors=\"pt\")`\n",
        "\n",
        "_L'importance de `padding` et `truncation` ne seront pas expliqué pour le moment._"
      ],
      "metadata": {
        "id": "JxLJO1fH3IvC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_tokens = # complétez ici\n",
        "val_tokens = # complétez ici\n",
        "test_tokens = # complétez ici"
      ],
      "metadata": {
        "id": "kMiuWn9c0spv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Dans la cellule ci-dessous, `print(.)` la séquence de tokens d'entraînement pour valider que le _tokenizer_ a bien fonctionné.**\n",
        "\n",
        "Vous devriez voir un _dictionnaire_ contenant un _tensor_ `input_ids` et un autre _tensor_ `attention_mask`.\n",
        "\n",
        "Un dictionnaire est un type natif à _Python_ qui permet d'associer des valeurs à des mots clef. C'est une structure de données qui permet une organisation simple de plusieurs valeurs."
      ],
      "metadata": {
        "id": "ANkgJEiq4HAR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# complétez ici"
      ],
      "metadata": {
        "id": "NmTWq8IY4SrJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4 : Créer le modèle de classification"
      ],
      "metadata": {
        "id": "FOhOwnnGC2jE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.1 Importer le module\n",
        "\n",
        "**Importez le sous-module `AutoModelForSequenceClassification` du module `transformers`**.\n",
        "\n",
        "Ce module nous permettra d'instancier un modèle de classification à partir de séquence de texte. Le modèle _BARThez_ est un modèle séquence à séquence, mais l'`AutoModelForSequenceClassification` permettra de créer un modèle de classification en utilisant l'encodeur préentraîné de _BARThez_.\n",
        "\n"
      ],
      "metadata": {
        "id": "n_MDRv99C86o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# complétez ici"
      ],
      "metadata": {
        "id": "qCTkMdVO4XI5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.2 Instanciation du modèle\n",
        "\n",
        "Instanciez le modèle à l'aide de la fonction `AutoModelForSequenceClassification.from_pretrained(.)`.\n",
        "\n",
        "En plus de donner le nom du modèle préentraîné à charger, il faut indiquer le nombre de classes possibles via le paramètre `num_labels = n_classes`.\n",
        "\n",
        "**Obtenez premièrement le nombre de classes et ensuite instanciez le modèle.\n",
        "Ne _hardcode_ pas le nombre de classes (5). Utilisez `len(.)` pour obtenir le nombre de classe de façon dynamique.**"
      ],
      "metadata": {
        "id": "S81VajU_F92l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_classes = # complétez ici\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"moussaKam/barthez\", num_labels=n_classes)"
      ],
      "metadata": {
        "id": "DcjeXjKEGBg5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5 : Création de _DataSet HuggingFace_"
      ],
      "metadata": {
        "id": "qvUbSgOzIOE8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.1 Classe personnalisée pour nos données\n",
        "Nous utilisons l'API d'_HuggingFace_ pour la creation du modèle de classification. Nous allons aussi l'utiliser pour l'entraînement du classifieur.\n",
        "\n",
        "l'API s'attend que nos données soient représentées dans des objets _PyTorch DataSet_.\n",
        "\n",
        "Il faut donc prendre nos dictionnaires `train_tokens`, `val_tokens` et `test_tokens` et nos _DataFrame_ `y_train`, `y_val` et `y_test` pour former 3 _DataSet_.\n",
        "\n",
        "**Exécutez la cellule ci-dessous pour déclarer une _classe Python_ qui représentera un _PyTorch DataSet_ de tickets de TI.**"
      ],
      "metadata": {
        "id": "0AmrrY9uIgUg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "import torch\n",
        "\n",
        "class TicketDataset(Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels  # This should be a flat list of ints\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: val[idx] for key, val in self.encodings.items()}\n",
        "        item[\"labels\"] = torch.tensor(self.labels[idx], dtype=torch.long)  # Force scalar tensor\n",
        "        return item\n"
      ],
      "metadata": {
        "id": "MPdkDTnhGeJp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.2 Créer les _DataSet_\n",
        "**Complétez la cellule ci-dessous afin d'instancier les trois _DataSet_.**"
      ],
      "metadata": {
        "id": "YDLVzuPzMsK8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = TicketDataset(train_tokens, y_train.tolist())\n",
        "val_dataset = # complétez ici\n",
        "test_dataset = # complétez ici"
      ],
      "metadata": {
        "id": "YKKO9oNeMtOn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6 : Entraînement du classifieur"
      ],
      "metadata": {
        "id": "PG1B5JU0ghcs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6.1 Configurer l'entraînement\n",
        "**Exécutez la cellule suivante**. Celle-ci créer un objet de configuration `training_args` qui contient des hyperparamètres pour l'entraînement (ex: _learning_rate_, _weight_decay_, etc.) et des informations pour le _logging_ avec _Weights & Biases_.\n",
        "\n",
        "Cette configuration sauvegarde les paramètres optimisés du modèle après chaque itération/époque.\n",
        "\n",
        "Dans ce cas, une itération contient 15 mises-à-jour/_steps_.\n",
        "\n",
        "Nous optimiserons le modèle pour 5 itérations, soit un total de 75 _steps_.\n",
        "\n",
        "Vous obtiendrez un répertoire contenant chaque sauvegarde. Une sauvegarde se nomme un _checkpoint_, en IA.\n",
        "\n",
        "<img src=\"https://i.ibb.co/4gNnBHb6/checkpoints.png\" width=\"20%\">"
      ],
      "metadata": {
        "id": "ca02R_rQV2YI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    logging_strategy=\"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    num_train_epochs=5,\n",
        "    weight_decay=0.01,\n",
        "    report_to=\"wandb\",\n",
        "    metric_for_best_model=\"f1\",\n",
        "    logging_dir=\"./logs\",\n",
        ")\n",
        "\n",
        "model.config.early_stopping = None\n",
        "model.config.num_beams = None\n",
        "model.config.no_repeat_ngram_size = None"
      ],
      "metadata": {
        "id": "qb25RRoeOFV9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6.2 Fonction pour évaluer la précision et score F1\n",
        "**Exécuter la cellule ci-dessous pour déclarer la fonction qui sera utilisée par l'entraîneur afin d'évaluer la précision et le score F1 du modèle.**"
      ],
      "metadata": {
        "id": "ij4IGp45hHlU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "\n",
        "    if isinstance(predictions, tuple):\n",
        "        predictions = predictions[0]\n",
        "\n",
        "    preds = np.argmax(predictions, axis=1)\n",
        "\n",
        "    return {\n",
        "        \"accuracy\": accuracy_score(labels, preds),\n",
        "        \"f1\": f1_score(labels, preds, average=\"weighted\")\n",
        "    }"
      ],
      "metadata": {
        "id": "ZJAras4VNCW-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6.3 Créer l'entraîneur avec l'API `Trainer` d'_HuggingFace_\n",
        "\n",
        "**Exécutez la cellule ci-dessous pour créer un objet `trainer`**. Celui-ci indique quel modèle entraîné la configuration ci-dessus et les jeux `train_dataset` et `val_dataset`."
      ],
      "metadata": {
        "id": "QQr9fXv1gmCF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Trainer\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    compute_metrics=compute_metrics\n",
        ")"
      ],
      "metadata": {
        "id": "QPn3Z_d3OHDA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6.4 Entraîner le modèle !\n",
        "**Exécutez la cellule ci-dessous pour démarrer l'entraînement.**\n",
        "\n",
        "Le paramètre `resume_from_checkpoint=False` est pour indiquer à l'entraîneur «recommencer de 0» l'entraînement, au lieu de continuer l'entraînement à partir du dernier _checkpoint_.\n",
        "\n",
        "**Après l'entraînement**, allez sur le projet «INF717-TP1» dans votre compte _Weights and Biases_ et observez les résultats. Les graphiques les plus importants pour nous sont :\n",
        "\n",
        "*   eval/loss\n",
        "*   train/loss\n",
        "*   eval/f1\n",
        "*   eval/accuracy"
      ],
      "metadata": {
        "id": "wfJwhTk5hdZE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "wandb.init(project=\"INF717-TP1\")\n",
        "trainer.train(resume_from_checkpoint=False)"
      ],
      "metadata": {
        "id": "zlr1ImJwOKyZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7 : Test du modèle\n",
        "\n",
        "**Exécutez les cellules suivantes pour évaluer le modèle sur le jeu de test.**"
      ],
      "metadata": {
        "id": "3Ll21awGixdv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_metrics = trainer.evaluate(test_dataset)\n",
        "print(test_metrics)"
      ],
      "metadata": {
        "id": "4P5ComDyjEKH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = trainer.predict(test_dataset)\n",
        "\n",
        "logits = predictions.predictions\n",
        "if isinstance(logits, tuple):\n",
        "    logits = logits[0]\n",
        "\n",
        "pred_labels = np.argmax(logits, axis=1)\n",
        "true_labels = predictions.label_ids\n",
        "\n",
        "for i in range(len(test_dataset)):\n",
        "    print(\"Description:\", X_test.iloc[i])\n",
        "    print(\"True label:\", encodeur.inverse_transform([true_labels[i]])[0])\n",
        "    print(\"Predicted:\", encodeur.inverse_transform([pred_labels[i]])[0])\n",
        "    print(\"-\" * 50)"
      ],
      "metadata": {
        "id": "QD231oGTjEdT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}